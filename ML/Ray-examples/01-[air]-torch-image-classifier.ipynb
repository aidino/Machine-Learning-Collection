{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Torch Image Classifier\n",
    "\n",
    "Source: https://docs.ray.io/en/latest/ray-air/examples/torch_image_example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "# !pip install 'ray[air]'\n",
    "# !pip install requests torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and normalize CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:53:50,487\tINFO worker.py:1612 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\"data\", download=True, train=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(\"data\", download=True, train=False)\n",
    "\n",
    "train_dataset: ray.data.Dataset = ray.data.from_torch(train_dataset)\n",
    "test_dataset: ray.data.Dataset = ray.data.from_torch(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, letâ€™s represent our data using a dictionary of ndarrays instead of tuples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:54:09,468\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(convert_batch_to_numpy)]\n",
      "2023-09-05 21:54:09,469\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-05 21:54:09,470\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f159aecbf6f460e9b3a4e2361b8d0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:54:10,678\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(convert_batch_to_numpy)]\n",
      "2023-09-05 21:54:10,678\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-05 21:54:10,678\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888c190aedca43d5b80a086d041bbb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:54:10,957\tWARNING plan.py:567 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "from PIL.Image import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "def convert_batch_to_numpy(batch) -> Dict[str, np.ndarray]:\n",
    "    images = np.stack([np.array(image) for image, _ in batch[\"item\"]])\n",
    "    labels = np.array([label for _, label in batch[\"item\"]])\n",
    "    return {\"image\": images, \"label\": labels}\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map_batches(convert_batch_to_numpy).materialize()\n",
    "test_dataset = test_dataset.map_batches(convert_batch_to_numpy).materialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c87236716e4fb9830bfcdebbe8a261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MaterializedDataset(\n",
       "   num_blocks=200,\n",
       "   num_rows=50000,\n",
       "   schema={image: numpy.ndarray(shape=(32, 32, 3), dtype=uint8), label: int64}\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import train\n",
    "from ray.air import session, Checkpoint\n",
    "from ray.train.torch import TorchCheckpoint\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    model = train.torch.prepare_model(Net())\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    train_dataset_shard = session.get_dataset_shard(\"train\")\n",
    "\n",
    "    for epoch in range(2):\n",
    "        running_loss = 0.0\n",
    "        train_dataset_batches = train_dataset_shard.iter_torch_batches(\n",
    "            batch_size=config[\"batch_size\"],\n",
    "        )\n",
    "        for i, batch in enumerate(train_dataset_batches):\n",
    "            # get the inputs and labels\n",
    "            inputs, labels = batch[\"image\"], batch[\"label\"]\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "        metrics = dict(running_loss=running_loss)\n",
    "        checkpoint = TorchCheckpoint.from_state_dict(model.state_dict())\n",
    "        session.report(metrics, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.data.preprocessors import TorchVisionPreprocessor\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "preprocessor = TorchVisionPreprocessor(columns=[\"image\"], transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-09-05 21:55:55</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:57.55        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.7/16.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  running_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_2eba9_00000</td><td>TERMINATED</td><td>127.0.0.1:27979</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         53.3442</td><td style=\"text-align: right;\">       625.659</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=27979)\u001b[0m The `preprocessor` arg to Trainer is deprecated. Apply preprocessor transformations ahead of time by calling `preprocessor.transform(ds)`. Support for the preprocessor arg will be dropped in a future release.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=27979)\u001b[0m Starting distributed worker processes: ['27981 (127.0.0.1)', '27982 (127.0.0.1)']\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=27981)\u001b[0m Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=27979)\u001b[0m Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(TorchVisionPreprocessor._transform_numpy)] -> AllToAllOperator[RandomizeBlockOrder]\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=27979)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=27979)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d20e1fd91343668e63512e7f54bc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=27979) - RandomizeBlockOrder 1:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46912969e7b44ecf90cbe36131cb567d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=27979) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=27981)\u001b[0m Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=27981)\u001b[0m Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=27982)\u001b[0m [1,  2000] loss: 2.244\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=27982)\u001b[0m [1,  6000] loss: 1.721\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=27982)\u001b[0m [1, 10000] loss: 1.503\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=27982)\u001b[0m [2,  2000] loss: 1.376\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=27982)\u001b[0m [2,  6000] loss: 1.354\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=27982)\u001b[0m [2, 10000] loss: 1.273\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 21:55:55,858\tINFO tune.py:1148 -- Total run time: 57.58 seconds (57.55 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\"batch_size\": 2},\n",
    "    datasets={\"train\": train_dataset},\n",
    "    scaling_config=ScalingConfig(num_workers=2),\n",
    "    preprocessor=preprocessor\n",
    ")\n",
    "result = trainer.fit()\n",
    "latest_checkpoint = result.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.torch import TorchPredictor\n",
    "from ray.train.batch_predictor import BatchPredictor\n",
    "\n",
    "batch_predictor = BatchPredictor.from_checkpoint(\n",
    "    checkpoint=latest_checkpoint,\n",
    "    predictor_cls=TorchPredictor,\n",
    "    model=Net(),\n",
    ")\n",
    "\n",
    "outputs: ray.data.Dataset = batch_predictor.predict(\n",
    "    data=test_dataset,\n",
    "    dtype=torch.float,\n",
    "    feature_columns=[\"image\"],\n",
    "    keep_columns=[\"label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 22:00:18,508\tINFO dataset.py:2180 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2023-09-05 22:00:18,511\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[MapBatches(TorchVisionPreprocessor._transform_numpy)->MapBatches(ScoringWrapper)] -> TaskPoolMapOperator[MapBatches(convert_logits_to_classes)]\n",
      "2023-09-05 22:00:18,511\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-05 22:00:18,512\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2023-09-05 22:00:18,531\tINFO actor_pool_map_operator.py:117 -- MapBatches(TorchVisionPreprocessor._transform_numpy)->MapBatches(ScoringWrapper): Waiting for 1 pool actors to start...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af15850d67f040fab847a8b9f2130298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 3, 'label': 3}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_logits_to_classes(df):\n",
    "    best_class = df[\"predictions\"].map(lambda x: x.argmax())\n",
    "    df[\"prediction\"] = best_class\n",
    "    return df[[\"prediction\", \"label\"]]\n",
    "\n",
    "predictions = outputs.map_batches(convert_logits_to_classes, batch_format=\"pandas\")\n",
    "\n",
    "predictions.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 22:00:50,895\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[MapBatches(TorchVisionPreprocessor._transform_numpy)->MapBatches(ScoringWrapper)] -> TaskPoolMapOperator[MapBatches(convert_logits_to_classes)->MapBatches(calculate_prediction_scores)]\n",
      "2023-09-05 22:00:50,900\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-05 22:00:50,903\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2023-09-05 22:00:50,928\tINFO actor_pool_map_operator.py:117 -- MapBatches(TorchVisionPreprocessor._transform_numpy)->MapBatches(ScoringWrapper): Waiting for 1 pool actors to start...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125b597261ff43f1915ebf0d4b9d11cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 22:00:53,209\tWARNING actor_pool_map_operator.py:267 -- To ensure full parallelization across an actor pool of size 1, the specified batch size should be at most 4050. Your configured batch size for this operator was 4096.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 3, 'label': 3, 'correct': True}\n"
     ]
    }
   ],
   "source": [
    "def calculate_prediction_scores(df):\n",
    "    df[\"correct\"] = df[\"prediction\"] == df[\"label\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "scores = predictions.map_batches(calculate_prediction_scores, batch_format=\"pandas\")\n",
    "\n",
    "scores.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 22:01:14,592\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[MapBatches(TorchVisionPreprocessor._transform_numpy)->MapBatches(ScoringWrapper)] -> TaskPoolMapOperator[MapBatches(convert_logits_to_classes)->MapBatches(calculate_prediction_scores)] -> AllToAllOperator[Aggregate]\n",
      "2023-09-05 22:01:14,592\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-05 22:01:14,593\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2023-09-05 22:01:14,612\tINFO actor_pool_map_operator.py:117 -- MapBatches(TorchVisionPreprocessor._transform_numpy)->MapBatches(ScoringWrapper): Waiting for 1 pool actors to start...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07d7570978047299b558dd58c95b36d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f682e0eff57a463d981f1eec76b52d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c54f36754541169a9880a29b822dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e982691b8d48428dd28dc16ccf7583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 22:01:17,571\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[MapBatches(TorchVisionPreprocessor._transform_numpy)->MapBatches(ScoringWrapper)] -> TaskPoolMapOperator[MapBatches(convert_logits_to_classes)->MapBatches(calculate_prediction_scores)]\n",
      "2023-09-05 22:01:17,580\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-05 22:01:17,587\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2023-09-05 22:01:17,606\tINFO actor_pool_map_operator.py:117 -- MapBatches(TorchVisionPreprocessor._transform_numpy)->MapBatches(ScoringWrapper): Waiting for 1 pool actors to start...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606bacd5404a419ba058508636e276d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5506"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sum(on=\"correct\") / scores.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the network and make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=29621)\u001b[0m INFO:     Started server process [29621]\n",
      "\u001b[2m\u001b[36m(ServeController pid=29619)\u001b[0m INFO 2023-09-05 22:02:40,557 controller 29619 deployment_state.py:1308 - Deploying new version of deployment default_PredictorDeployment.\n",
      "\u001b[2m\u001b[36m(ServeController pid=29619)\u001b[0m INFO 2023-09-05 22:02:40,660 controller 29619 deployment_state.py:1571 - Adding 1 replica to deployment default_PredictorDeployment.\n",
      "2023-09-05 22:02:42,475\tINFO router.py:853 -- Using PowerOfTwoChoicesReplicaScheduler.\n",
      "2023-09-05 22:02:42,483\tINFO router.py:329 -- Got updated replicas for deployment default_PredictorDeployment: {'default_PredictorDeployment#DUcTXi'}.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayServeSyncHandle(deployment='default_PredictorDeployment')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray import serve\n",
    "from ray.serve import PredictorDeployment\n",
    "from ray.serve.http_adapters import json_to_ndarray\n",
    "\n",
    "\n",
    "serve.run(\n",
    "    PredictorDeployment.bind(\n",
    "        TorchPredictor,\n",
    "        latest_checkpoint,\n",
    "        model=Net(),\n",
    "        http_adapter=json_to_ndarray,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = test_dataset.take(1)[0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [-110.8222427368164,\n",
       "  1.1426030397415161,\n",
       "  -103.1728286743164,\n",
       "  165.62962341308594,\n",
       "  -172.87025451660156,\n",
       "  196.0765380859375,\n",
       "  28.147117614746094,\n",
       "  -22.12794303894043,\n",
       "  92.32986450195312,\n",
       "  -194.28038024902344]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ServeReplica:default_PredictorDeployment pid=29622)\u001b[0m INFO 2023-09-05 22:04:48,846 default_PredictorDeployment default_PredictorDeployment#DUcTXi fvIHieyWEi / default replica.py:723 - __CALL__ OK 15.5ms\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "payload = {\"array\": image.tolist(), \"dtype\": \"float32\"}\n",
    "response = requests.post(\"http://localhost:8000/\", json=payload)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
