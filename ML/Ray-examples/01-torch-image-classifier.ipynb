{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Torch Image Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "# !pip install 'ray[air]'\n",
    "# !pip install requests torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and normalize CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 17:06:24,781\tINFO worker.py:1612 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\"data\", download=True, train=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(\"data\", download=True, train=False)\n",
    "\n",
    "train_dataset: ray.data.Dataset = ray.data.from_torch(train_dataset)\n",
    "test_dataset: ray.data.Dataset = ray.data.from_torch(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, letâ€™s represent our data using a dictionary of ndarrays instead of tuples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 17:06:49,828\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(convert_batch_to_numpy)]\n",
      "2023-09-05 17:06:49,828\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-05 17:06:49,829\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19123bb5d71f4c56a89e48e7c11ed9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 17:06:50,857\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(convert_batch_to_numpy)]\n",
      "2023-09-05 17:06:50,857\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-09-05 17:06:50,858\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d866d2e437a54bca9a5f686d90d9f39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "from PIL.Image import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "def convert_batch_to_numpy(batch) -> Dict[str, np.ndarray]:\n",
    "    images = np.stack([np.array(image) for image, _ in batch[\"item\"]])\n",
    "    labels = np.array([label for _, label in batch[\"item\"]])\n",
    "    return {\"image\": images, \"label\": labels}\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map_batches(convert_batch_to_numpy).materialize()\n",
    "test_dataset = test_dataset.map_batches(convert_batch_to_numpy).materialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb74308c0ee42d99938a352404714a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MaterializedDataset(\n",
       "   num_blocks=200,\n",
       "   num_rows=50000,\n",
       "   schema={image: numpy.ndarray(shape=(32, 32, 3), dtype=uint8), label: int64}\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
