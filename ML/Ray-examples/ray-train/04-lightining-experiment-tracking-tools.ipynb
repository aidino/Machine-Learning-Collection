{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Experiment Tracking Tools in LightningTrainer\n",
    "\n",
    "- `W&B`, `CometML`, `MLFlow`, and `Tensorboard` are all popular tools in the field of machine learning for managing, visualizing, and tracking experiments. \n",
    "\n",
    "The `LightningTrainer` integration in Ray AIR allows you to continue using these built-in experiment tracking integrations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your model and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create dummy data\n",
    "X = torch.randn(128, 3)  # 128 samples, 3 features\n",
    "y = torch.randint(0, 2, (128,))  # 128 binary labels\n",
    "\n",
    "# create a TensorDataset to wrap the data\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# create a DataLoader to iterate over the dataset\n",
    "batch_size = 8\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dummy model\n",
    "class DummyModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = torch.nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat.flatten(), y.float())\n",
    "\n",
    "        # The metrics below will be reported to Loggers\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log_dict({\"metric_1\": 1 / (batch_idx + 1), \"metric_2\": batch_idx * 100})\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "from pytorch_lightning.loggers.comet import CometLogger\n",
    "from pytorch_lightning.loggers.mlflow import MLFlowLogger\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "from pytorch_lightning.utilities.rank_zero import rank_zero_only # Avoid creating a new experiment run on the driver node.\n",
    "import wandb\n",
    "\n",
    "\n",
    "# A callback to login wandb in each worker\n",
    "class WandbLoginCallback(pl.Callback):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def setup(self, trainer, pl_module, stage) -> None:\n",
    "        wandb.login(key=self.key)\n",
    "\n",
    "\n",
    "def create_loggers(name, project_name, save_dir=\"./logs\", offline=False):\n",
    "    # Avoid creating a new experiment run on the driver node.\n",
    "    rank_zero_only.rank = None\n",
    "\n",
    "    # Wandb\n",
    "    # wandb_api_key = os.environ.get(\"WANDB_API_KEY\", None)\n",
    "\n",
    "    # class RayWandbLogger(WandbLogger):\n",
    "    #     # wandb.finish() ensures all artifacts get uploaded at the end of training.\n",
    "    #     def finalize(self, status):\n",
    "    #         super().finalize(status)\n",
    "    #         wandb.finish()\n",
    "\n",
    "    # wandb_logger = RayWandbLogger(\n",
    "    #     name=name, \n",
    "    #     project=project_name, \n",
    "    #     # Specify a unique id to avoid reporting to a new run after restoration\n",
    "    #     id=\"unique_id\", \n",
    "    #     save_dir=f\"{save_dir}/wandb\", \n",
    "    #     offline=offline\n",
    "    # )\n",
    "    # callbacks = [] if offline else [WandbLoginCallback(key=wandb_api_key)]\n",
    "\n",
    "    # # CometML\n",
    "    # comet_api_key = os.environ.get(\"COMET_API_KEY\", None)\n",
    "    # comet_logger = CometLogger(\n",
    "    #     api_key=comet_api_key,\n",
    "    #     experiment_name=name,\n",
    "    #     project_name=project_name,\n",
    "    #     save_dir=f\"{save_dir}/comet\",\n",
    "    #     offline=offline,\n",
    "    # )\n",
    "\n",
    "    # MLFlow\n",
    "    mlflow_logger = MLFlowLogger(\n",
    "        run_name=name,\n",
    "        experiment_name=project_name,\n",
    "        tracking_uri=f\"file:{save_dir}/mlflow\",\n",
    "    )\n",
    "\n",
    "    # Tensorboard\n",
    "    tensorboard_logger = TensorBoardLogger(\n",
    "        name=name, save_dir=f\"{save_dir}/tensorboard\"\n",
    "    )\n",
    "\n",
    "    # return [wandb_logger, comet_logger, mlflow_logger, tensorboard_logger], callbacks\n",
    "    return [mlflow_logger, tensorboard_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_SAVE_DIR = \"./logs\"\n",
    "# loggers, callbacks = create_loggers(\n",
    "#     name=\"demo-run\", project_name=\"demo-project\", save_dir=YOUR_SAVE_DIR, offline=False\n",
    "# )\n",
    "loggers = create_loggers(\n",
    "    name=\"demo-run\", project_name=\"demo-project\", save_dir=YOUR_SAVE_DIR, offline=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model and view logged results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-09-07 17:54:19</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:10.18        </td></tr>\n",
       "<tr><td>Memory:      </td><td>7.3/30.9 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 5.0/20 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  metric_1</th><th style=\"text-align: right;\">  metric_2</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>LightningTrainer_df06c_00000</td><td>TERMINATED</td><td>192.168.33.188:15261</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">          5.1021</td><td style=\"text-align: right;\">    0.804872</td><td style=\"text-align: right;\">      0.25</td><td style=\"text-align: right;\">       300</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 17:54:08,877\tINFO data_parallel_trainer.py:404 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=15261)\u001b[0m GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(LightningTrainer pid=15261)\u001b[0m GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(LightningTrainer pid=15261)\u001b[0m Starting distributed worker processes: ['15402 (192.168.33.188)', '15403 (192.168.33.188)', '15404 (192.168.33.188)', '15405 (192.168.33.188)']\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m Setting up process group for: env:// [rank=0, world_size=4]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m Experiment with name demo-project not found. Creating it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 4/4 [00:00<00:00, 126.18it/s, v_num=a8_0]\n",
      "Epoch 1: 100%|██████████| 4/4 [00:00<00:00, 172.09it/s, v_num=a8_0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m   | Name  | Type   | Params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m ---------------------------------\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m 0 | layer | Linear | 4     \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m ---------------------------------\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m 4         Trainable params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m 4         Total params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m 0.000     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m /home/mpp/miniconda3/envs/ray-torch/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m /home/mpp/miniconda3/envs/ray-torch/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('metric_2', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m   warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s, v_num=a8_0]         \n",
      "Epoch 2: 100%|██████████| 4/4 [00:00<00:00, 127.38it/s, v_num=a8_0]\n",
      "Epoch 3: 100%|██████████| 4/4 [00:00<00:00, 120.59it/s, v_num=a8_0]\n",
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 238.28it/s, v_num=a8_0]\n",
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 28.23it/s, v_num=a8_0] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=15402)\u001b[0m `Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "2023-09-07 17:54:19,059\tINFO tune.py:1148 -- Total run time: 10.20 seconds (10.18 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'_report_on': 'train_epoch_end', 'train_loss': 0.8048718571662903, 'metric_1': 0.25, 'metric_2': 300.0, 'epoch': 4, 'step': 20, 'should_checkpoint': True, 'done': True, 'trial_id': 'df06c_00000', 'experiment_tag': '0'},\n",
       "  path='/tmp/ray_results/ptl-exp-tracking/LightningTrainer_df06c_00000_0_2023-09-07_17-54-08',\n",
       "  checkpoint=LightningCheckpoint(local_path=/tmp/ray_results/ptl-exp-tracking/LightningTrainer_df06c_00000_0_2023-09-07_17-54-08/checkpoint_000004)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.air.config import RunConfig, ScalingConfig\n",
    "from ray.train.lightning import LightningConfigBuilder, LightningTrainer\n",
    "\n",
    "builder = LightningConfigBuilder()\n",
    "builder.module(cls=DummyModel)\n",
    "builder.trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"cpu\",\n",
    "    logger=loggers,\n",
    "    log_every_n_steps=1,\n",
    ")\n",
    "builder.fit_params(train_dataloaders=dataloader)\n",
    "\n",
    "lightning_config = builder.build()\n",
    "\n",
    "scaling_config = ScalingConfig(num_workers=4, use_gpu=False)\n",
    "\n",
    "run_config = RunConfig(\n",
    "    name=\"ptl-exp-tracking\",\n",
    "    storage_path=\"/tmp/ray_results\",\n",
    ")\n",
    "\n",
    "trainer = LightningTrainer(\n",
    "    lightning_config=lightning_config,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
